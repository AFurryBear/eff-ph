{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/u/yxiong/eff-ph/utils/')\n",
    "sys.path.append('/u/yxiong/vis_utils/')\n",
    "from utils import get_path, read_ripser_result, compute_ph\n",
    "from io_utils import dist_kwargs_to_str\n",
    "from toydata_utils import get_toy_data\n",
    "from dist_utils import get_dist\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# Hyperparameters\n",
    "#####################################################################\n",
    "\n",
    "dataset = \"toy_circle\"  # must be one of toy_circle, toy_sphere, torus, eyeglasses, inter_circles, toy_blob, two_rings\n",
    "d = 2  # ambient dimension\n",
    "max_dim = 1  # dimension of highest dimensional topological features computed\n",
    "\n",
    "sigmas = np.linspace(0.0, 0.35, 29)\n",
    "sigmas = np.array([np.format_float_positional(sigma, precision=4, unique=True, trim='0') for sigma in sigmas]).astype(float)\n",
    "\n",
    "distances = {\n",
    "    # \"euclidean\": [{}],\n",
    "    # \"fermat\": [\n",
    "    #            {\"p\": 1},\n",
    "    #            {\"p\": 2},\n",
    "    #            {\"p\": 3},\n",
    "    #            {\"p\": 5},\n",
    "    #            {\"p\": 7}\n",
    "    #            ],\n",
    "    \"dtm\": [\n",
    "            {\"k\": 4, \"p_dtm\": 2, \"p_radius\": 1},\n",
    "            {\"k\": 4, \"p_dtm\": np.inf, \"p_radius\": 1},\n",
    "            {\"k\": 15, \"p_dtm\": 2, \"p_radius\": 1},\n",
    "            {\"k\": 15, \"p_dtm\": np.inf, \"p_radius\": 1},\n",
    "            {\"k\": 100, \"p_dtm\": 2, \"p_radius\": 1},\n",
    "            {\"k\": 100, \"p_dtm\": np.inf, \"p_radius\": 1},\n",
    "            {\"k\": 4, \"p_dtm\": 2, \"p_radius\": 2},\n",
    "            {\"k\": 4, \"p_dtm\": np.inf, \"p_radius\": 2},\n",
    "            {\"k\": 15, \"p_dtm\": 2, \"p_radius\": 2},\n",
    "            {\"k\": 15, \"p_dtm\": np.inf, \"p_radius\": 2},\n",
    "            {\"k\": 100, \"p_dtm\": 2, \"p_radius\": 2},\n",
    "            {\"k\": 100, \"p_dtm\": np.inf, \"p_radius\": 2},\n",
    "            {\"k\": 4, \"p_dtm\": 2, \"p_radius\": np.inf},\n",
    "            {\"k\": 4, \"p_dtm\": np.inf, \"p_radius\": np.inf},\n",
    "            {\"k\": 15, \"p_dtm\": 2, \"p_radius\": np.inf},\n",
    "            {\"k\": 15, \"p_dtm\": np.inf, \"p_radius\": np.inf},\n",
    "            {\"k\": 100, \"p_dtm\": 2, \"p_radius\": np.inf},\n",
    "            {\"k\": 100, \"p_dtm\": np.inf, \"p_radius\": np.inf},\n",
    "    ],\n",
    "    \"core\": [\n",
    "        {\"k\": 15},\n",
    "        {\"k\": 100}\n",
    "    ],\n",
    "    \"sknn_dist\": [\n",
    "        {\"k\": 15},\n",
    "        {\"k\": 100}\n",
    "    ],\n",
    "    \"tsne\": [\n",
    "         {\"perplexity\": 30},\n",
    "         {\"perplexity\": 200},\n",
    "         {\"perplexity\": 333}\n",
    "    ],\n",
    "    \"umap\": [\n",
    "         {\"k\": 100, \"use_rho\": True, \"include_self\": True},\n",
    "         {\"k\": 999, \"use_rho\": True, \"include_self\": True},\n",
    "    ],\n",
    "    \"tsne_embd\": [\n",
    "        {\"perplexity\": 8, \"n_epochs\": 500, \"n_early_epochs\": 250, \"rescale_tsne\": True},\n",
    "        {\"perplexity\": 30, \"n_epochs\": 500, \"n_early_epochs\": 250, \"rescale_tsne\": True},\n",
    "        {\"perplexity\": 333, \"n_epochs\": 500, \"n_early_epochs\": 250, \"rescale_tsne\": True}\n",
    "    ],\n",
    "    \"umap_embd\": [\n",
    "        {\"k\": 15, \"n_epochs\": 750, \"min_dist\": 0.1, \"metric\": \"euclidean\"},\n",
    "        {\"k\": 100, \"n_epochs\": 750, \"min_dist\": 0.1, \"metric\": \"euclidean\"},\n",
    "        {\"k\": 999, \"n_epochs\": 750, \"min_dist\": 0.1, \"metric\": \"euclidean\"},\n",
    "    ],\n",
    "    \"eff_res\": [\n",
    "        {\"corrected\": True, \"weighted\": False, \"k\": 15, \"disconnect\": True},\n",
    "        {\"corrected\": True, \"weighted\": False, \"k\": 100, \"disconnect\": True}\n",
    "    ],\n",
    "    \"diffusion\": [\n",
    "        {\"k\": 15, \"t\": 8, \"kernel\": \"sknn\", \"include_self\": False},\n",
    "        {\"k\": 100, \"t\": 8, \"kernel\": \"sknn\", \"include_self\": False},\n",
    "        {\"k\": 15, \"t\": 64, \"kernel\": \"sknn\", \"include_self\": False},\n",
    "        {\"k\": 100, \"t\": 64, \"kernel\": \"sknn\", \"include_self\": False},\n",
    "    ],\n",
    "    \"spectral\": [\n",
    "        {\"k\": 15, \"normalization\": \"none\", \"n_evecs\": 2, \"weighted\": False},\n",
    "        {\"k\": 15, \"normalization\": \"none\", \"n_evecs\": 5, \"weighted\": False},\n",
    "        {\"k\": 15, \"normalization\": \"none\", \"n_evecs\": 10, \"weighted\": False},\n",
    "    ],\n",
    "}\n",
    "\n",
    "seeds = [0, 1, 2]\n",
    "\n",
    "n = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_euclidean\n",
      "Computing PH for toy_circle with sigma 0.0 and distance euclidean with {}\n",
      "Writing dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_euclidean\n",
      "Running Ripser for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_euclidean\n",
      "Deleting dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_euclidean\n",
      "\n",
      "\n",
      "Starting with toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_1\n",
      "Computing PH for toy_circle with sigma 0.0 and distance fermat with {'p': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: ../ripser//ripser-representatives: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_1\n",
      "Running Ripser for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_1\n",
      "Deleting dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_1\n",
      "\n",
      "\n",
      "Starting with toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_2\n",
      "Computing PH for toy_circle with sigma 0.0 and distance fermat with {'p': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: ../ripser//ripser-representatives: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_2\n",
      "Running Ripser for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_2\n",
      "Deleting dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_2\n",
      "\n",
      "\n",
      "Starting with toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_3\n",
      "Computing PH for toy_circle with sigma 0.0 and distance fermat with {'p': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: ../ripser//ripser-representatives: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_3\n",
      "Running Ripser for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_3\n",
      "Deleting dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_3\n",
      "\n",
      "\n",
      "Starting with toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_5\n",
      "Computing PH for toy_circle with sigma 0.0 and distance fermat with {'p': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: ../ripser//ripser-representatives: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_5\n",
      "Running Ripser for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_5\n",
      "Deleting dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_5\n",
      "\n",
      "\n",
      "Starting with toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_7\n",
      "Computing PH for toy_circle with sigma 0.0 and distance fermat with {'p': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: ../ripser//ripser-representatives: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_7\n",
      "Running Ripser for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_7\n",
      "Deleting dists for toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_fermat_p_7\n",
      "\n",
      "\n",
      "Starting with toy_circle_1000_d_2_ortho_gauss_sigma_0.0_seed_0_dtm_k_4_p_dtm_2_p_radius_1\n",
      "Computing PH for toy_circle with sigma 0.0 and distance dtm with {'k': 4, 'p_dtm': 2, 'p_radius': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bash: ../ripser//ripser-representatives: No such file or directory\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_76200/4279070916.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                                         \"seed\": seed})\n\u001b[1;32m     35\u001b[0m                 \u001b[0;31m# compute the distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdist_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# compute peristent homology\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_ph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelete_dists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eff-ph/utils/dist_utils.py\u001b[0m in \u001b[0;36mget_dist\u001b[0;34m(x, distance, input_distance, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sp_sknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dtm\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dtm_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fermat\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fermat_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eff-ph/utils/dist_utils.py\u001b[0m in \u001b[0;36mget_dtm_weights\u001b[0;34m(x, k, p_dtm, p_radius, input_distance)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\"\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# get distance to measure for each point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp_dtm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# compute input distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/eff-ph/utils/dist_utils.py\u001b[0m in \u001b[0;36mget_dtm\u001b[0;34m(x, k, p, input_distance)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpairwise\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mknn_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkNN_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_distance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# cannot use np.linalg.norm due to factor 1/k in the root of the mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vis_utils/vis_utils/utils.py\u001b[0m in \u001b[0;36mkNN_dists\u001b[0;34m(x, k, metric)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mk\u001b[0m \u001b[0mnearest\u001b[0m \u001b[0mneighbors\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \"\"\"\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeops_dists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0mknn_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdists\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# use k+1 neighbours and omit first, which is just the point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/vis_utils/vis_utils/utils.py\u001b[0m in \u001b[0;36mkeops_dists\u001b[0;34m(x, metric)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlazytensor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \"\"\"\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"correlation\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# mean center so that we can then do the same thing as for cosine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "\n",
    "root_path = '/u/yxiong/eff-ph/data'\n",
    "\n",
    "for seed in seeds:\n",
    "    for sigma in sigmas:\n",
    "        # get data\n",
    "        x = get_toy_data(n=n, dataset=dataset, d=d, seed=seed, **{\"gaussian\": {\"sigma\": sigma}})\n",
    "        # compute PH\n",
    "        for distance in distances:\n",
    "            for dist_kwargs in distances[distance]:\n",
    "                file_name = f\"{dataset}_{n}_d_{d}_ortho_gauss_sigma_{sigma}_seed_{seed}_{distance}\" \\\n",
    "                            + dist_kwargs_to_str(dist_kwargs)\n",
    "                print(f\"Starting with {file_name}\")\n",
    "                folder_path = os.path.join(root_path,dataset)\n",
    "                os.makedirs(folder_path,exist_ok=True)\n",
    "                file_path = os.path.join(root_path, dataset, file_name+\"_rep\")\n",
    "                 \n",
    "                # try to load precomputed result\n",
    "                #try:\n",
    "                    #res = read_ripser_result(os.path.join(root_path, dataset, file_name+\"_rep\"))\n",
    "                # if non-existent compute PH\n",
    "                #except FileNotFoundError:\n",
    "                print(f\"Computing PH for {dataset} with sigma {sigma} and distance {distance} with {dist_kwargs}\")\n",
    "\n",
    "                # copy the dict bc we will change it for the embedding based approaches, so that we can nicely save\n",
    "                # the embedding as well\n",
    "                dist_kwargs = dist_kwargs.copy()\n",
    "\n",
    "                # update the distance with embedding parameters, needed for saving the embedding itself\n",
    "                if distance.endswith(\"embd\"):\n",
    "                    dist_kwargs.update({\"root_path\": os.path.join(root_path, dataset),\n",
    "                                        \"dataset\": f\"n_{n}_d_{d}_ortho_gauss_sigma_{sigma}\",\n",
    "                                        \"seed\": seed})\n",
    "                # compute the distance\n",
    "                dists = get_dist(x=x, distance=distance, **dist_kwargs)\n",
    "                # compute peristent homology\n",
    "                res = compute_ph(dists, file_name, root_path, dataset, dim=max_dim, delete_dists=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
